{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "deffcacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, linear_model, metrics, pipeline, preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "152f0e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "92b4abfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://stepik.org/media/attachments/lesson/85567/_3afd3252820d8a4e1c5c9148bb0ec3a5_bike_sharing_demand.csv', header=0, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "78e91130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
       "0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "2  2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
       "3  2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
       "4  2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
       "\n",
       "   humidity  windspeed  casual  registered  count  \n",
       "0        81        0.0       3          13     16  \n",
       "1        80        0.0       8          32     40  \n",
       "2        80        0.0       5          27     32  \n",
       "3        75        0.0       3          10     13  \n",
       "4        75        0.0       0           1      1  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "51204f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.datetime = data.datetime.apply(pd.to_datetime)\n",
    "data['month'] = data.datetime.apply(lambda x : x.month)\n",
    "data['hour'] = data.datetime.apply(lambda x : x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "51fecb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9886, 14) (1000, 14)\n"
     ]
    }
   ],
   "source": [
    "train_data = data[:-1000]\n",
    "test_data = data[-1000:]\n",
    "\n",
    "print(train_data.shape, test_data.shape)\n",
    "\n",
    "train_labels = train_data['count']\n",
    "train_data = train_data.drop(['datetime', 'count', 'casual', 'registered'], axis=1)\n",
    "\n",
    "test_labels = test_data['count']\n",
    "test_data = test_data.drop(['datetime', 'count', 'casual', 'registered'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "62d51e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_data_columns = ['holiday', 'workingday']\n",
    "binary_data_indices = np.array([(column in binary_data_columns) for column in train_data.columns], dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "19a39fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['holiday', 'workingday']\n",
      "[False  True  True False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "print(binary_data_columns)\n",
    "print(binary_data_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "47a17219",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data_columns = ['season', 'weather', 'month']\n",
    "categorical_data_indices = np.array([(column in categorical_data_columns) for column in train_data.columns], dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1f744e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['season', 'weather', 'month']\n",
      "[ True False False  True False False False False  True False]\n"
     ]
    }
   ],
   "source": [
    "print(categorical_data_columns)\n",
    "print(categorical_data_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e3846049",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data_columns = ['temp', 'atemp', 'humidity', 'windspeed', 'hour']\n",
    "numeric_data_indices = np.array([(column in numeric_data_columns) for column in train_data.columns], dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a8d4f1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['temp', 'atemp', 'humidity', 'windspeed', 'hour']\n",
      "[False False False False  True  True  True  True False  True]\n"
     ]
    }
   ],
   "source": [
    "print(numeric_data_columns)\n",
    "print(numeric_data_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "aa37417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = linear_model.SGDRegressor(random_state=0, max_iter=3, loss='squared_loss', penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b2558b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = pipeline.Pipeline(steps = [\n",
    "    ('feature_processing', pipeline.FeatureUnion(transformer_list = [\n",
    "        \n",
    "        ('binary_variables_processing', preprocessing.FunctionTransformer(lambda data: data.iloc[:, binary_data_indices])),\n",
    "        \n",
    "        ('numeric_variables_processing', pipeline.Pipeline(steps = [\n",
    "            ('selecting', preprocessing.FunctionTransformer(lambda data: data.iloc[:, numeric_data_indices])),\n",
    "            ('scaling', preprocessing.StandardScaler(with_mean=0.0))\n",
    "        ])),\n",
    "        \n",
    "        ('categorical_variables_processing', pipeline.Pipeline(steps = [\n",
    "            ('selecting', preprocessing.FunctionTransformer(lambda data: data.iloc[:, categorical_data_indices])),\n",
    "            ('hot_encoding', preprocessing.OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]))\n",
    "        \n",
    "        \n",
    "    ])),\n",
    "    ('model_fitting', regressor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f13d0025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feature_processing',\n",
       "                 FeatureUnion(transformer_list=[('binary_variables_processing',\n",
       "                                                 FunctionTransformer(func=<function <lambda> at 0x000001F0B90CE0D0>)),\n",
       "                                                ('numeric_variables_processing',\n",
       "                                                 Pipeline(steps=[('selecting',\n",
       "                                                                  FunctionTransformer(func=<function <lambda> at 0x000001F0B90CE280>)),\n",
       "                                                                 ('scaling',\n",
       "                                                                  StandardScaler(with_mean=0.0))])),\n",
       "                                                ('categorical_variables_processing',\n",
       "                                                 Pipeline(steps=[('selecting',\n",
       "                                                                  FunctionTransformer(func=<function <lambda> at 0x000001F0B90CE5E0>)),\n",
       "                                                                 ('hot_encoding',\n",
       "                                                                  OneHotEncoder(handle_unknown='ignore'))]))])),\n",
       "                ('model_fitting',\n",
       "                 SGDRegressor(loss='squared_loss', max_iter=3,\n",
       "                              random_state=0))])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "baa136f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120.17177172806856"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_error(test_labels, estimator.predict(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2b0a8745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory\n",
      "steps\n",
      "verbose\n",
      "feature_processing\n",
      "model_fitting\n",
      "feature_processing__n_jobs\n",
      "feature_processing__transformer_list\n",
      "feature_processing__transformer_weights\n",
      "feature_processing__verbose\n",
      "feature_processing__binary_variables_processing\n",
      "feature_processing__numeric_variables_processing\n",
      "feature_processing__categorical_variables_processing\n",
      "feature_processing__binary_variables_processing__accept_sparse\n",
      "feature_processing__binary_variables_processing__check_inverse\n",
      "feature_processing__binary_variables_processing__func\n",
      "feature_processing__binary_variables_processing__inv_kw_args\n",
      "feature_processing__binary_variables_processing__inverse_func\n",
      "feature_processing__binary_variables_processing__kw_args\n",
      "feature_processing__binary_variables_processing__validate\n",
      "feature_processing__numeric_variables_processing__memory\n",
      "feature_processing__numeric_variables_processing__steps\n",
      "feature_processing__numeric_variables_processing__verbose\n",
      "feature_processing__numeric_variables_processing__selecting\n",
      "feature_processing__numeric_variables_processing__scaling\n",
      "feature_processing__numeric_variables_processing__selecting__accept_sparse\n",
      "feature_processing__numeric_variables_processing__selecting__check_inverse\n",
      "feature_processing__numeric_variables_processing__selecting__func\n",
      "feature_processing__numeric_variables_processing__selecting__inv_kw_args\n",
      "feature_processing__numeric_variables_processing__selecting__inverse_func\n",
      "feature_processing__numeric_variables_processing__selecting__kw_args\n",
      "feature_processing__numeric_variables_processing__selecting__validate\n",
      "feature_processing__numeric_variables_processing__scaling__copy\n",
      "feature_processing__numeric_variables_processing__scaling__with_mean\n",
      "feature_processing__numeric_variables_processing__scaling__with_std\n",
      "feature_processing__categorical_variables_processing__memory\n",
      "feature_processing__categorical_variables_processing__steps\n",
      "feature_processing__categorical_variables_processing__verbose\n",
      "feature_processing__categorical_variables_processing__selecting\n",
      "feature_processing__categorical_variables_processing__hot_encoding\n",
      "feature_processing__categorical_variables_processing__selecting__accept_sparse\n",
      "feature_processing__categorical_variables_processing__selecting__check_inverse\n",
      "feature_processing__categorical_variables_processing__selecting__func\n",
      "feature_processing__categorical_variables_processing__selecting__inv_kw_args\n",
      "feature_processing__categorical_variables_processing__selecting__inverse_func\n",
      "feature_processing__categorical_variables_processing__selecting__kw_args\n",
      "feature_processing__categorical_variables_processing__selecting__validate\n",
      "feature_processing__categorical_variables_processing__hot_encoding__categories\n",
      "feature_processing__categorical_variables_processing__hot_encoding__drop\n",
      "feature_processing__categorical_variables_processing__hot_encoding__dtype\n",
      "feature_processing__categorical_variables_processing__hot_encoding__handle_unknown\n",
      "feature_processing__categorical_variables_processing__hot_encoding__sparse\n",
      "model_fitting__alpha\n",
      "model_fitting__average\n",
      "model_fitting__early_stopping\n",
      "model_fitting__epsilon\n",
      "model_fitting__eta0\n",
      "model_fitting__fit_intercept\n",
      "model_fitting__l1_ratio\n",
      "model_fitting__learning_rate\n",
      "model_fitting__loss\n",
      "model_fitting__max_iter\n",
      "model_fitting__n_iter_no_change\n",
      "model_fitting__penalty\n",
      "model_fitting__power_t\n",
      "model_fitting__random_state\n",
      "model_fitting__shuffle\n",
      "model_fitting__tol\n",
      "model_fitting__validation_fraction\n",
      "model_fitting__verbose\n",
      "model_fitting__warm_start\n"
     ]
    }
   ],
   "source": [
    "print(*estimator.get_params().keys(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "74ed0bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_grid = {\n",
    "    'model_fitting__alpha': [0.0001, 0.001, 0.1],\n",
    "    'model_fitting__eta0': [0.001, 0.05]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d7438864",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = model_selection.GridSearchCV(estimator, parameters_grid, scoring='neg_mean_absolute_error', cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b6855bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=Pipeline(steps=[('feature_processing',\n",
       "                                        FeatureUnion(transformer_list=[('binary_variables_processing',\n",
       "                                                                        FunctionTransformer(func=<function <lambda> at 0x000001F0B90CE0D0>)),\n",
       "                                                                       ('numeric_variables_processing',\n",
       "                                                                        Pipeline(steps=[('selecting',\n",
       "                                                                                         FunctionTransformer(func=<function <lambda> at 0x000001F0B90CE280>)),\n",
       "                                                                                        ('scaling',\n",
       "                                                                                         StandardScaler(wit...\n",
       "                                                                        Pipeline(steps=[('selecting',\n",
       "                                                                                         FunctionTransformer(func=<function <lambda> at 0x000001F0B90CE5E0>)),\n",
       "                                                                                        ('hot_encoding',\n",
       "                                                                                         OneHotEncoder(handle_unknown='ignore'))]))])),\n",
       "                                       ('model_fitting',\n",
       "                                        SGDRegressor(loss='squared_loss',\n",
       "                                                     max_iter=3,\n",
       "                                                     random_state=0))]),\n",
       "             param_grid={'model_fitting__alpha': [0.0001, 0.001, 0.1],\n",
       "                         'model_fitting__eta0': [0.001, 0.05]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b6cb63c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_absolute_percentage_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'rand_score',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'top_k_accuracy',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "265d77d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-104.61466553476612\n",
      "{'model_fitting__alpha': 0.1, 'model_fitting__eta0': 0.05}\n"
     ]
    }
   ],
   "source": [
    "print(grid_cv.best_score_)\n",
    "print(grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "64eca7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = grid_cv.best_estimator_.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7e851f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126.17670701473044"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_error(test_labels, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a6f96bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[525, 835, 355, 222, 228, 325, 328, 308, 346, 446, 943, 838, 531, 432, 195, 181, 199, 49, 17, 16]\n"
     ]
    }
   ],
   "source": [
    "print(list(test_labels[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f166b40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[143.24, 166.19, 212.42, 243.67, 262.21, 255.96, 280.36, 307.47, 313.16, 323.56, 320.61, 313.13, 294.67, 279.5, 269.68, 240.32, 244.88, 52.83, 60.38, 67.93]\n"
     ]
    }
   ],
   "source": [
    "print([round(x, 2) for x in test_predictions[:20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d1b5ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6d58ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = RandomForestRegressor(random_state=0, max_depth=20, n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "96cae3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_rg = pipeline.Pipeline(steps = [\n",
    "    ('feature_processing', pipeline.FeatureUnion(transformer_list = [\n",
    "        \n",
    "        ('binary_variables_processing', preprocessing.FunctionTransformer(lambda data: data.iloc[:, binary_data_indices])),\n",
    "        \n",
    "        ('numeric_variables_processing', pipeline.Pipeline(steps = [\n",
    "            ('selecting', preprocessing.FunctionTransformer(lambda data: data.iloc[:, numeric_data_indices])),\n",
    "            ('scaling', preprocessing.StandardScaler(with_mean=0.0))\n",
    "        ])),\n",
    "        \n",
    "        ('categorical_variables_processing', pipeline.Pipeline(steps = [\n",
    "            ('selecting', preprocessing.FunctionTransformer(lambda data: data.iloc[:, categorical_data_indices])),\n",
    "            ('hot_encoding', preprocessing.OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]))\n",
    "        \n",
    "        \n",
    "    ])),\n",
    "    ('model_fitting', rg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "21e7706b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feature_processing',\n",
       "                 FeatureUnion(transformer_list=[('binary_variables_processing',\n",
       "                                                 FunctionTransformer(func=<function <lambda> at 0x000001F0BA7F0280>)),\n",
       "                                                ('numeric_variables_processing',\n",
       "                                                 Pipeline(steps=[('selecting',\n",
       "                                                                  FunctionTransformer(func=<function <lambda> at 0x000001F0BA8DF1F0>)),\n",
       "                                                                 ('scaling',\n",
       "                                                                  StandardScaler(with_mean=0.0))])),\n",
       "                                                ('categorical_variables_processing',\n",
       "                                                 Pipeline(steps=[('selecting',\n",
       "                                                                  FunctionTransformer(func=<function <lambda> at 0x000001F0BA8DF310>)),\n",
       "                                                                 ('hot_encoding',\n",
       "                                                                  OneHotEncoder(handle_unknown='ignore'))]))])),\n",
       "                ('model_fitting',\n",
       "                 RandomForestRegressor(max_depth=20, n_estimators=50,\n",
       "                                       random_state=0))])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_rg.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8e7ac1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f0b90b7a60>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(train_labels, estimator_rg.predict(train_data), color='red')\n",
    "plt.scatter(test_labels, estimator_rg.predict(test_data), color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c9ae8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
